# -*- coding: utf-8 -*-
"""labwork.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16jHux-ktNMkuCyNdc1bWsN2MA7W4calB
"""

!pip install numba-cuda[cu12]

from numba import cuda

#cuda.detect()
gpu = cuda.gpus[0]

print("Name of the GPU : ")
print(gpu.name) #Name of the GPU
print("MULTIPROCESSOR COUNT : ")
print(gpu.MULTIPROCESSOR_COUNT) #Multiprocessor count of the gpu

meminfo = cuda.current_context().get_memory_info()

print("free memory :")
print(meminfo[0] / 1e9)
print("total memory :")
print(meminfo[1] / 1e9)

cuda.close()